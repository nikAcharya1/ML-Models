{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab374648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "\n",
    "img_width, img_height = 224, 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ece99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'v_data/train'\n",
    "validation_data_dir = 'v_data/test'\n",
    "nb_train_samples =400\n",
    "nb_validation_samples = 100\n",
    "epochs = 10\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61de7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "\tinput_shape = (3, img_width, img_height)\n",
    "else:\n",
    "\tinput_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07a84a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765f038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "\t\t\toptimizer='rmsprop',\n",
    "\t\t\tmetrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4483b9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tabal\\AppData\\Local\\Temp\\ipykernel_17044\\64122331.py:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25/25 [==============================] - 12s 467ms/step - loss: 0.8084 - accuracy: 0.5475 - val_loss: 0.5638 - val_accuracy: 0.7396\n",
      "Epoch 2/10\n",
      "25/25 [==============================] - 12s 462ms/step - loss: 0.5805 - accuracy: 0.7100 - val_loss: 0.3903 - val_accuracy: 0.8542\n",
      "Epoch 3/10\n",
      "25/25 [==============================] - 11s 452ms/step - loss: 0.4865 - accuracy: 0.7750 - val_loss: 0.3411 - val_accuracy: 0.8750\n",
      "Epoch 4/10\n",
      "25/25 [==============================] - 12s 461ms/step - loss: 0.4322 - accuracy: 0.8125 - val_loss: 0.3161 - val_accuracy: 0.8854\n",
      "Epoch 5/10\n",
      "25/25 [==============================] - 11s 449ms/step - loss: 0.3929 - accuracy: 0.8275 - val_loss: 0.3190 - val_accuracy: 0.8750\n",
      "Epoch 6/10\n",
      "25/25 [==============================] - 11s 445ms/step - loss: 0.3499 - accuracy: 0.8750 - val_loss: 0.2819 - val_accuracy: 0.8854\n",
      "Epoch 7/10\n",
      "25/25 [==============================] - 12s 490ms/step - loss: 0.3569 - accuracy: 0.8575 - val_loss: 0.2737 - val_accuracy: 0.8854\n",
      "Epoch 8/10\n",
      "25/25 [==============================] - 12s 461ms/step - loss: 0.3222 - accuracy: 0.8750 - val_loss: 0.2872 - val_accuracy: 0.8854\n",
      "Epoch 9/10\n",
      "25/25 [==============================] - 11s 451ms/step - loss: 0.3176 - accuracy: 0.8500 - val_loss: 0.3042 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "25/25 [==============================] - 12s 471ms/step - loss: 0.2749 - accuracy: 0.8875 - val_loss: 0.2583 - val_accuracy: 0.8958\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17bfab52170>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "\trescale=1. / 255,\n",
    "\tshear_range=0.2,\n",
    "\tzoom_range=0.2,\n",
    "\thorizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\ttrain_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\tvalidation_data_dir,\n",
    "\ttarget_size=(img_width, img_height),\n",
    "\tbatch_size=batch_size,\n",
    "\tclass_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
    "\tepochs=epochs,\n",
    "\tvalidation_data=validation_generator,\n",
    "\tvalidation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c63e1be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_saved.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffcd4eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 80ms/step\n",
      "Predicted Class (0 - Cars , 1- Planes):  0.02\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('model_saved.h5')\n",
    "\n",
    "\n",
    "image = load_img('v_data/csketch.jpg', target_size=(224, 224))\n",
    "img = np.array(image)\n",
    "img = img / 255.0\n",
    "img = img.reshape(1,224,224,3)\n",
    "label = model.predict(img)\n",
    "print(\"Predicted Class (0 - Cars , 1- Planes): \", round(label[0][0], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04c8ac5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
